{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fcf3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "#def read_txt(file_name):\n",
    "   # with open(file_name, \"r\", encoding='UTF8') as txt_file:\n",
    "        #return txt_file.read()\n",
    "def read_txt(file_name):\n",
    "    with open(file_name, \"r\", encoding='ISO-8859-1') as txt_file:\n",
    "        return txt_file.read()\n",
    "\n",
    "def extract(text_initial):\n",
    "    start_index = text_initial.find('<DOCUMENT>') + len('<DOCUMENT>')\n",
    "    end_index = text_initial.find('</DOCUMENT>')\n",
    "    return text_initial[start_index:end_index]\n",
    "\n",
    "def BeautifulSoup_clean1(extracted_content):\n",
    "    soup = BeautifulSoup(extracted_content, 'html.parser')\n",
    "    return soup.get_text()\n",
    "\n",
    "def further_clean(text):\n",
    "    for a_sign in ['\\\\n', '\\\\t', '☐', '☒', '\\xa0', '●', '“', '”']:\n",
    "        text = text.replace(a_sign, \" \")\n",
    "    for a_punc in string.punctuation:\n",
    "        text = text.replace(a_punc, \" \")\n",
    "    return re.sub('\\s+', \" \", text).lower().strip()\n",
    "\n",
    "def word_count(text):\n",
    "    word_list = word_tokenize(text)\n",
    "    total_num = len(word_list)\n",
    "    return total_num, word_list\n",
    "\n",
    "def filter_words(word_list):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    pattern = re.compile(r'[\\d\\W]')\n",
    "    filtered_list = [word for word in word_list if word not in stop_words and not pattern.search(word) and len(word) > 1]\n",
    "    return len(filtered_list), filtered_list\n",
    "\n",
    "def process_file(file_name):\n",
    "    text_initial = read_txt(file_name)\n",
    "    extracted_content = extract(text_initial)\n",
    "    cleaned_text = further_clean(BeautifulSoup_clean1(extracted_content))\n",
    "    total_num, word_list = word_count(cleaned_text)\n",
    "    word_count_filtered, filtered_list = filter_words(word_list)\n",
    "    return word_count_filtered, filtered_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8127105c",
   "metadata": {},
   "source": [
    "### test code for 14 files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4386758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mitunl/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mitunl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the folder name: test\n",
      "Files to be processed: ['A_0001090872-20-000004.txt : 20200303.txt', 'A_0001090872-18-000004.txt : 20180306.txt', 'A_0001090872-19-000006.txt : 20190305.txt', 'A_0001090872-22-000007.txt : 20220303.txt', 'A_0001090872-19-000015.txt : 20190830.txt', 'A_0001090872-18-000015.txt : 20180830.txt', 'A_0001090872-21-000009.txt : 20210601.txt', 'A_0001090872-22-000012.txt : 20220531.txt', 'A_0001090872-19-000010.txt : 20190530.txt', 'A_0001090872-21-000015.txt : 20210901.txt', 'A_0001090872-18-000009.txt : 20180531.txt', 'A_0001090872-21-000004.txt : 20210302.txt', 'A_0001090872-20-000014.txt : 20200901.txt', 'A_0001090872-22-000017.txt : 20220901.txt', 'A_0001090872-20-000010.txt : 20200601.txt']\n",
      "Continue processing? (yes/no): yes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_all_files(folder_name):\n",
    "    \"\"\"Extract all filenames with .txt extension from the given directory\"\"\"\n",
    "    all_files = [f for f in os.listdir(folder_name) if os.path.isfile(os.path.join(folder_name, f)) and f.endswith('.txt')]\n",
    "    return all_files\n",
    "\n",
    "\n",
    "def process_directory(folder_name, files_list):\n",
    "    # Initialize an empty dataframe\n",
    "    df = pd.DataFrame(columns=[\"ticker\", \"file_number\", \"date\", \"word_count\", \"words\"])\n",
    "    data = []\n",
    "\n",
    "    # Iterate over each file in the provided files list\n",
    "    for file_name in files_list:\n",
    "        # Full path to the file\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "        \n",
    "        # Process the file\n",
    "        count, words = process_file(file_path)\n",
    "\n",
    "        # Extract ticker, file_number, and date from the file_name\n",
    "        ticker = file_name.split('_')[0]\n",
    "        file_number = file_name.split('_')[1].split(' : ')[0]\n",
    "        date_str = file_name.split(' : ')[1].split('.txt')[0]\n",
    "        \n",
    "        # Convert date string to actual date format\n",
    "        date = pd.to_datetime(date_str, format='%Y%m%d')\n",
    "\n",
    "        # Append results to the data list\n",
    "        data.append({\n",
    "            \"ticker\": ticker,\n",
    "            \"file_number\": file_number,\n",
    "            \"date\": date,\n",
    "            \"word_count\": count,\n",
    "            \"words\": words\n",
    "        })\n",
    "\n",
    "    # Convert data list to a DataFrame and concatenate with the original df\n",
    "    df = pd.concat([df, pd.DataFrame(data)], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # You need to have nltk's resources downloaded to run the program\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "    folder_name = input(\"Enter the folder name: \")\n",
    "    \n",
    "    all_files = get_all_files(folder_name)\n",
    "    print(\"Files to be processed:\", all_files)\n",
    "    \n",
    "    confirmation = input(\"Continue processing? (yes/no): \").strip().lower()\n",
    "    if confirmation == 'yes':\n",
    "        results_df = process_directory(folder_name, all_files)\n",
    "      \n",
    "    else:\n",
    "        print(\"Processing aborted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "172997f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>file_number</th>\n",
       "      <th>date</th>\n",
       "      <th>word_count</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-20-000004.txt</td>\n",
       "      <td>2020-03-03</td>\n",
       "      <td>18292</td>\n",
       "      <td>[htm, document, accelerated, us, gaap, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-18-000004.txt</td>\n",
       "      <td>2018-03-06</td>\n",
       "      <td>16522</td>\n",
       "      <td>[htm, document, table, contentsunited, statess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-19-000006.txt</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>17730</td>\n",
       "      <td>[htm, document, table, contentsunited, statess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-22-000007.txt</td>\n",
       "      <td>2022-03-03</td>\n",
       "      <td>18088</td>\n",
       "      <td>[htm, gaap, gaap, gaap, gaap, usdxbrli, gaap, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-19-000015.txt</td>\n",
       "      <td>2019-08-30</td>\n",
       "      <td>20449</td>\n",
       "      <td>[htm, document, accelerated, us, gaap, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-18-000015.txt</td>\n",
       "      <td>2018-08-30</td>\n",
       "      <td>18482</td>\n",
       "      <td>[htm, document, table, contentsunited, statess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-21-000009.txt</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>20499</td>\n",
       "      <td>[htm, gaap, gaap, gaap, gaap, gaap, gaap, gaap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-22-000012.txt</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>20064</td>\n",
       "      <td>[htm, gaap, gaap, gaap, gaap, gaap, gaap, gaap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-19-000010.txt</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>19174</td>\n",
       "      <td>[htm, document, table, contentsunited, statess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-21-000015.txt</td>\n",
       "      <td>2021-09-01</td>\n",
       "      <td>20441</td>\n",
       "      <td>[htm, gaap, gaap, gaap, gaap, gaap, gaap, gaap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-18-000009.txt</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>18391</td>\n",
       "      <td>[htm, document, table, contentsunited, statess...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-21-000004.txt</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>18519</td>\n",
       "      <td>[htm, gaap, gaap, gaap, gaap, usdxbrli, gaap, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-20-000014.txt</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>22376</td>\n",
       "      <td>[htm, document, accelerated, us, gaap, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-22-000017.txt</td>\n",
       "      <td>2022-09-01</td>\n",
       "      <td>20096</td>\n",
       "      <td>[htm, fasb, org, us, gaap, otherassetsnoncurre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A</td>\n",
       "      <td>0001090872-20-000010.txt</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>21760</td>\n",
       "      <td>[htm, document, accelerated, us, gaap, product...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ticker               file_number       date word_count  \\\n",
       "0       A  0001090872-20-000004.txt 2020-03-03      18292   \n",
       "1       A  0001090872-18-000004.txt 2018-03-06      16522   \n",
       "2       A  0001090872-19-000006.txt 2019-03-05      17730   \n",
       "3       A  0001090872-22-000007.txt 2022-03-03      18088   \n",
       "4       A  0001090872-19-000015.txt 2019-08-30      20449   \n",
       "5       A  0001090872-18-000015.txt 2018-08-30      18482   \n",
       "6       A  0001090872-21-000009.txt 2021-06-01      20499   \n",
       "7       A  0001090872-22-000012.txt 2022-05-31      20064   \n",
       "8       A  0001090872-19-000010.txt 2019-05-30      19174   \n",
       "9       A  0001090872-21-000015.txt 2021-09-01      20441   \n",
       "10      A  0001090872-18-000009.txt 2018-05-31      18391   \n",
       "11      A  0001090872-21-000004.txt 2021-03-02      18519   \n",
       "12      A  0001090872-20-000014.txt 2020-09-01      22376   \n",
       "13      A  0001090872-22-000017.txt 2022-09-01      20096   \n",
       "14      A  0001090872-20-000010.txt 2020-06-01      21760   \n",
       "\n",
       "                                                words  \n",
       "0   [htm, document, accelerated, us, gaap, product...  \n",
       "1   [htm, document, table, contentsunited, statess...  \n",
       "2   [htm, document, table, contentsunited, statess...  \n",
       "3   [htm, gaap, gaap, gaap, gaap, usdxbrli, gaap, ...  \n",
       "4   [htm, document, accelerated, us, gaap, product...  \n",
       "5   [htm, document, table, contentsunited, statess...  \n",
       "6   [htm, gaap, gaap, gaap, gaap, gaap, gaap, gaap...  \n",
       "7   [htm, gaap, gaap, gaap, gaap, gaap, gaap, gaap...  \n",
       "8   [htm, document, table, contentsunited, statess...  \n",
       "9   [htm, gaap, gaap, gaap, gaap, gaap, gaap, gaap...  \n",
       "10  [htm, document, table, contentsunited, statess...  \n",
       "11  [htm, gaap, gaap, gaap, gaap, usdxbrli, gaap, ...  \n",
       "12  [htm, document, accelerated, us, gaap, product...  \n",
       "13  [htm, fasb, org, us, gaap, otherassetsnoncurre...  \n",
       "14  [htm, document, accelerated, us, gaap, product...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6610d9",
   "metadata": {},
   "source": [
    "### processing all the files in the form of small chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc89a79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mitunl/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mitunl/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the folder name: 10-Q\n",
      "Total files to be processed: 7304\n",
      "Processing chunk 1 out of 16...\n",
      "Processed 456 files in chunk 1.\n",
      "Time taken for chunk 1: 317.7752001285553 seconds\n",
      "Saved chunk 1 to chunk_1.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 2 out of 16...\n",
      "Processed 456 files in chunk 2.\n",
      "Time taken for chunk 2: 353.67844581604004 seconds\n",
      "Saved chunk 2 to chunk_2.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 3 out of 16...\n",
      "Processed 456 files in chunk 3.\n",
      "Time taken for chunk 3: 376.4825930595398 seconds\n",
      "Saved chunk 3 to chunk_3.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 4 out of 16...\n",
      "Processed 456 files in chunk 4.\n",
      "Time taken for chunk 4: 396.8757908344269 seconds\n",
      "Saved chunk 4 to chunk_4.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 5 out of 16...\n",
      "Processed 456 files in chunk 5.\n",
      "Time taken for chunk 5: 439.02630400657654 seconds\n",
      "Saved chunk 5 to chunk_5.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 6 out of 16...\n",
      "Processed 456 files in chunk 6.\n",
      "Time taken for chunk 6: 464.30269598960876 seconds\n",
      "Saved chunk 6 to chunk_6.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 7 out of 16...\n",
      "Processed 456 files in chunk 7.\n",
      "Time taken for chunk 7: 564.060898065567 seconds\n",
      "Saved chunk 7 to chunk_7.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 8 out of 16...\n",
      "Processed 456 files in chunk 8.\n",
      "Time taken for chunk 8: 1549.548406124115 seconds\n",
      "Saved chunk 8 to chunk_8.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 9 out of 16...\n",
      "Processed 456 files in chunk 9.\n",
      "Time taken for chunk 9: 1875.527019739151 seconds\n",
      "Saved chunk 9 to chunk_9.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 10 out of 16...\n",
      "Processed 456 files in chunk 10.\n",
      "Time taken for chunk 10: 1995.5928778648376 seconds\n",
      "Saved chunk 10 to chunk_10.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 11 out of 16...\n",
      "Processed 456 files in chunk 11.\n",
      "Time taken for chunk 11: 2159.4697930812836 seconds\n",
      "Saved chunk 11 to chunk_11.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 12 out of 16...\n",
      "Processed 456 files in chunk 12.\n",
      "Time taken for chunk 12: 2206.5165009498596 seconds\n",
      "Saved chunk 12 to chunk_12.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 13 out of 16...\n",
      "Processed 456 files in chunk 13.\n",
      "Time taken for chunk 13: 2494.366333961487 seconds\n",
      "Saved chunk 13 to chunk_13.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 14 out of 16...\n",
      "Processed 456 files in chunk 14.\n",
      "Time taken for chunk 14: 2630.0162551403046 seconds\n",
      "Saved chunk 14 to chunk_14.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 15 out of 16...\n",
      "Processed 456 files in chunk 15.\n",
      "Time taken for chunk 15: 2752.612327814102 seconds\n",
      "Saved chunk 15 to chunk_15.csv\n",
      "Continue processing the next chunk? (yes/no): yes\n",
      "Processing chunk 16 out of 16...\n",
      "Processed 456 files in chunk 16.\n",
      "Time taken for chunk 16: 2891.8313941955566 seconds\n",
      "Saved chunk 16 to chunk_16.csv\n",
      "Processing chunk 17 out of 16...\n",
      "Processed 8 files in chunk 17.\n",
      "Time taken for chunk 17: 56.25332999229431 seconds\n",
      "Saved chunk 17 to chunk_17.csv\n",
      "Processing completed.\n"
     ]
    }
   ],
   "source": [
    "import time  # Import the time module\n",
    "\n",
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import nltk  # You need to import the nltk package\n",
    "    # ... [rest of the imports]\n",
    "\n",
    "    # You need to have nltk's resources downloaded to run the program\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "    folder_name = input(\"Enter the folder name: \")\n",
    "    all_files = get_all_files(folder_name)\n",
    "    print(\"Total files to be processed:\", len(all_files))\n",
    "    \n",
    "    chunk_size = len(all_files) // 16  # Divide the files into 16 chunks\n",
    "    file_chunks = list(chunks(all_files, chunk_size))\n",
    "\n",
    "    all_dataframes = []  # This will store all the dataframes\n",
    "\n",
    "    for index, file_chunk in enumerate(file_chunks):\n",
    "        print(f\"Processing chunk {index+1} out of 16...\")\n",
    "        \n",
    "        start_time = time.time()  # Record the start time\n",
    "        \n",
    "        # Process the chunk of files\n",
    "        results_df_chunk = process_directory(folder_name, file_chunk)\n",
    "        all_dataframes.append(results_df_chunk)\n",
    "        \n",
    "        end_time = time.time()  # Record the end time\n",
    "        elapsed_time = end_time - start_time  # Calculate the elapsed time\n",
    "        \n",
    "        # Print the number of files processed and the time taken\n",
    "        print(f\"Processed {len(file_chunk)} files in chunk {index+1}.\")\n",
    "        print(f\"Time taken for chunk {index+1}: {elapsed_time} seconds\")\n",
    "        \n",
    "        # Save the processed chunk to a CSV for safety\n",
    "        results_df_chunk.to_csv(f\"chunk_{index+1}.csv\", index=False)\n",
    "        print(f\"Saved chunk {index+1} to chunk_{index+1}.csv\")\n",
    "        \n",
    "        # If not the last chunk, ask for permission to continue\n",
    "        if index < 15:\n",
    "            confirmation = input(\"Continue processing the next chunk? (yes/no): \").strip().lower()\n",
    "            if confirmation != 'yes':\n",
    "                print(\"Processing aborted.\")\n",
    "                break\n",
    "\n",
    "    # Combine all dataframes\n",
    "    final_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "    \n",
    "    print(\"Processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ec4b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df\n",
    "final_df.to_csv('cleaned_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b281432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>file_number</th>\n",
       "      <th>date</th>\n",
       "      <th>word_count</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNA</td>\n",
       "      <td>0000091440-21-000011.txt</td>\n",
       "      <td>2021-04-22</td>\n",
       "      <td>13001</td>\n",
       "      <td>[sna, htm, sna, gaap, gaap, propertyplantandeq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCK</td>\n",
       "      <td>0000927653-20-000093.txt</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>17989</td>\n",
       "      <td>[mck, htm, mck, gaap, gaap, usdxbrli, gaap, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HSIC</td>\n",
       "      <td>0001000228-20-000055.txt</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>20228</td>\n",
       "      <td>[htm, quarterly, report, truetruemodified, var...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CME</td>\n",
       "      <td>0001156375-21-000052.txt</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>7184</td>\n",
       "      <td>[cme, htm, cme, gaap, gaap, gaap, gaap, gaap, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTW</td>\n",
       "      <td>0001564590-18-026537.txt</td>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>24493</td>\n",
       "      <td>[wltw, htm, wltw, htm, united, states, securit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>MCK</td>\n",
       "      <td>0000927653-21-000065.txt</td>\n",
       "      <td>2021-08-05</td>\n",
       "      <td>14680</td>\n",
       "      <td>[mck, htm, mck, gaap, usdxbrli, gaap, gaap, ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>YUM</td>\n",
       "      <td>0001041061-19-000048.txt</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>10695</td>\n",
       "      <td>[yum, htm, document, false, yum, refranchising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>PARA</td>\n",
       "      <td>0000813828-19-000033.txt</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>18320</td>\n",
       "      <td>[htm, document, us, gaap, commonclassamember, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>TMUS</td>\n",
       "      <td>0001283699-22-000117.txt</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>14902</td>\n",
       "      <td>[tmus, htm, tmus, form, tmus, usdxbrli, gaap, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>DISH</td>\n",
       "      <td>0001558370-20-013008.txt</td>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>38968</td>\n",
       "      <td>[dish, htm, gaap, deferredlongtermliabilitycha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7304 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker               file_number       date word_count  \\\n",
       "0       SNA  0000091440-21-000011.txt 2021-04-22      13001   \n",
       "1       MCK  0000927653-20-000093.txt 2020-11-03      17989   \n",
       "2      HSIC  0001000228-20-000055.txt 2020-08-04      20228   \n",
       "3       CME  0001156375-21-000052.txt 2021-05-05       7184   \n",
       "4       WTW  0001564590-18-026537.txt 2018-11-02      24493   \n",
       "...     ...                       ...        ...        ...   \n",
       "7299    MCK  0000927653-21-000065.txt 2021-08-05      14680   \n",
       "7300    YUM  0001041061-19-000048.txt 2019-11-05      10695   \n",
       "7301   PARA  0000813828-19-000033.txt 2019-11-12      18320   \n",
       "7302   TMUS  0001283699-22-000117.txt 2022-07-29      14902   \n",
       "7303   DISH  0001558370-20-013008.txt 2020-11-06      38968   \n",
       "\n",
       "                                                  words  \n",
       "0     [sna, htm, sna, gaap, gaap, propertyplantandeq...  \n",
       "1     [mck, htm, mck, gaap, gaap, usdxbrli, gaap, ga...  \n",
       "2     [htm, quarterly, report, truetruemodified, var...  \n",
       "3     [cme, htm, cme, gaap, gaap, gaap, gaap, gaap, ...  \n",
       "4     [wltw, htm, wltw, htm, united, states, securit...  \n",
       "...                                                 ...  \n",
       "7299  [mck, htm, mck, gaap, usdxbrli, gaap, gaap, ga...  \n",
       "7300  [yum, htm, document, false, yum, refranchising...  \n",
       "7301  [htm, document, us, gaap, commonclassamember, ...  \n",
       "7302  [tmus, htm, tmus, form, tmus, usdxbrli, gaap, ...  \n",
       "7303  [dish, htm, gaap, deferredlongtermliabilitycha...  \n",
       "\n",
       "[7304 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7574be5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# (1) Gather the S&P 500 historical close prices\n",
    "sp500 = yf.Ticker('^GSPC')\n",
    "history = sp500.history(period='1d', start='2017-06-01', end='2023-02-01')['Close']\n",
    "mk_returns = history / history.shift(1) - 1\n",
    "mk_returns.dropna(inplace=True)\n",
    "mk_returns.index = mk_returns.index.strftime('%Y-%m-%d')\n",
    "mk_returns.name = 'market_returns'\n",
    "def previous_bd(date):\n",
    "    return (datetime.strptime(date, \"%Y-%m-%d\") + timedelta(days=-1)).strftime('%Y-%m-%d')\n",
    "\n",
    "# (2) Define your function to gather market returns\n",
    "def get_mk_returns(data):\n",
    "    filing_date = data['date']\n",
    "    while not filing_date in mk_returns.index:\n",
    "        filing_date = (datetime.strptime(filing_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    n_row = mk_returns.index.get_loc(filing_date)\n",
    "    start_date = mk_returns.index[n_row - 120]\n",
    "    end_date = mk_returns.index[n_row]\n",
    "    window = np.logical_and(mk_returns.index >= start_date, mk_returns.index < end_date)\n",
    "    return mk_returns[window]\n",
    "\n",
    "# (3) Define your function to gather past returns of a given ticker\n",
    "def get_ticker_past_returns(data):\n",
    "    filing_date = data['date']\n",
    "    ticker = data['ticker']\n",
    "    while not filing_date in mk_returns.index:\n",
    "        filing_date = (datetime.strptime(filing_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    n_row = mk_returns.index.get_loc(filing_date)\n",
    "    start_date = mk_returns.index[n_row - 121]\n",
    "    end_date = mk_returns.index[n_row]\n",
    "    history = yf.Ticker(ticker).history(period='1d', start=start_date, end=end_date)['Close']\n",
    "    returns = history / history.shift(1) - 1\n",
    "    returns.dropna(inplace=True)\n",
    "    returns.index = returns.index.strftime('%Y-%m-%d')\n",
    "    returns.name = ticker\n",
    "    return returns\n",
    "\n",
    "# (4) Define your function to compute beta\n",
    "def get_beta(data):\n",
    "    series1 = get_ticker_past_returns(data)\n",
    "    series2 = get_mk_returns(data)\n",
    "    ts1_reset = series1.reset_index()\n",
    "    ts2_reset = series2.reset_index()\n",
    "    merged = pd.merge(ts1_reset, ts2_reset, on='Date', how='inner')\n",
    "    merged.set_index('Date', inplace=True)\n",
    "    merged = sm.add_constant(merged)\n",
    "    model = sm.OLS(merged.iloc[:, 2], merged.iloc[:, :2])\n",
    "    results = model.fit()\n",
    "    beta = results.params[data['ticker']]\n",
    "    return beta\n",
    "\n",
    "# (5) Define your function to compute excess returns\n",
    "def excess_returns(data):\n",
    "    filing_date = data['date']\n",
    "    ticker = data['ticker']\n",
    "    while not filing_date in mk_returns.index:\n",
    "        filing_date = (datetime.strptime(filing_date, \"%Y-%m-%d\") + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    n_row = mk_returns.index.get_loc(filing_date)\n",
    "    start_date = mk_returns.index[n_row + 1]\n",
    "    end_date = mk_returns.index[n_row + 4]\n",
    "    history = yf.Ticker(ticker).history(period='1d', start=previous_bd(start_date), end=end_date)['Close']\n",
    "    if history.empty:\n",
    "        return np.nan\n",
    "    returns = history / history.shift(1) - 1\n",
    "    returns.dropna(inplace=True)\n",
    "    returns.index = returns.index.strftime('%Y-%m-%d')\n",
    "    sum_returns = sum(returns)\n",
    "    beta = get_beta(data)\n",
    "    sum_mk_returns = sum(mk_returns.iloc[n_row + 1:n_row + 4])\n",
    "    return sum_returns - beta * sum_mk_returns\n",
    "result_df = pd.read_csv('cleaned_text.csv')\n",
    "\n",
    "# Assuming result_df is already loaded and contains 'ticker' and 'filing_date' columns\n",
    "result_df['excess_returns'] = result_df.apply(excess_returns, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fecb8a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>file_number</th>\n",
       "      <th>date</th>\n",
       "      <th>word_count</th>\n",
       "      <th>words</th>\n",
       "      <th>excess_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNA</td>\n",
       "      <td>0000091440-21-000011.txt</td>\n",
       "      <td>2021-04-22</td>\n",
       "      <td>13001</td>\n",
       "      <td>['sna', 'htm', 'sna', 'gaap', 'gaap', 'propert...</td>\n",
       "      <td>-0.003843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MCK</td>\n",
       "      <td>0000927653-20-000093.txt</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>17989</td>\n",
       "      <td>['mck', 'htm', 'mck', 'gaap', 'gaap', 'usdxbrl...</td>\n",
       "      <td>0.052555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HSIC</td>\n",
       "      <td>0001000228-20-000055.txt</td>\n",
       "      <td>2020-08-04</td>\n",
       "      <td>20228</td>\n",
       "      <td>['htm', 'quarterly', 'report', 'truetruemodifi...</td>\n",
       "      <td>-0.027407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CME</td>\n",
       "      <td>0001156375-21-000052.txt</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>7184</td>\n",
       "      <td>['cme', 'htm', 'cme', 'gaap', 'gaap', 'gaap', ...</td>\n",
       "      <td>0.023516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WTW</td>\n",
       "      <td>0001564590-18-026537.txt</td>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>24493</td>\n",
       "      <td>['wltw', 'htm', 'wltw', 'htm', 'united', 'stat...</td>\n",
       "      <td>0.015161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7299</th>\n",
       "      <td>MCK</td>\n",
       "      <td>0000927653-21-000065.txt</td>\n",
       "      <td>2021-08-05</td>\n",
       "      <td>14680</td>\n",
       "      <td>['mck', 'htm', 'mck', 'gaap', 'usdxbrli', 'gaa...</td>\n",
       "      <td>-0.023552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7300</th>\n",
       "      <td>YUM</td>\n",
       "      <td>0001041061-19-000048.txt</td>\n",
       "      <td>2019-11-05</td>\n",
       "      <td>10695</td>\n",
       "      <td>['yum', 'htm', 'document', 'false', 'yum', 're...</td>\n",
       "      <td>0.008845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7301</th>\n",
       "      <td>PARA</td>\n",
       "      <td>0000813828-19-000033.txt</td>\n",
       "      <td>2019-11-12</td>\n",
       "      <td>18320</td>\n",
       "      <td>['htm', 'document', 'us', 'gaap', 'commonclass...</td>\n",
       "      <td>0.019004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7302</th>\n",
       "      <td>TMUS</td>\n",
       "      <td>0001283699-22-000117.txt</td>\n",
       "      <td>2022-07-29</td>\n",
       "      <td>14902</td>\n",
       "      <td>['tmus', 'htm', 'tmus', 'form', 'tmus', 'usdxb...</td>\n",
       "      <td>-0.004576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7303</th>\n",
       "      <td>DISH</td>\n",
       "      <td>0001558370-20-013008.txt</td>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>38968</td>\n",
       "      <td>['dish', 'htm', 'gaap', 'deferredlongtermliabi...</td>\n",
       "      <td>0.074702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7304 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker               file_number        date  word_count  \\\n",
       "0       SNA  0000091440-21-000011.txt  2021-04-22       13001   \n",
       "1       MCK  0000927653-20-000093.txt  2020-11-03       17989   \n",
       "2      HSIC  0001000228-20-000055.txt  2020-08-04       20228   \n",
       "3       CME  0001156375-21-000052.txt  2021-05-05        7184   \n",
       "4       WTW  0001564590-18-026537.txt  2018-11-02       24493   \n",
       "...     ...                       ...         ...         ...   \n",
       "7299    MCK  0000927653-21-000065.txt  2021-08-05       14680   \n",
       "7300    YUM  0001041061-19-000048.txt  2019-11-05       10695   \n",
       "7301   PARA  0000813828-19-000033.txt  2019-11-12       18320   \n",
       "7302   TMUS  0001283699-22-000117.txt  2022-07-29       14902   \n",
       "7303   DISH  0001558370-20-013008.txt  2020-11-06       38968   \n",
       "\n",
       "                                                  words  excess_returns  \n",
       "0     ['sna', 'htm', 'sna', 'gaap', 'gaap', 'propert...       -0.003843  \n",
       "1     ['mck', 'htm', 'mck', 'gaap', 'gaap', 'usdxbrl...        0.052555  \n",
       "2     ['htm', 'quarterly', 'report', 'truetruemodifi...       -0.027407  \n",
       "3     ['cme', 'htm', 'cme', 'gaap', 'gaap', 'gaap', ...        0.023516  \n",
       "4     ['wltw', 'htm', 'wltw', 'htm', 'united', 'stat...        0.015161  \n",
       "...                                                 ...             ...  \n",
       "7299  ['mck', 'htm', 'mck', 'gaap', 'usdxbrli', 'gaa...       -0.023552  \n",
       "7300  ['yum', 'htm', 'document', 'false', 'yum', 're...        0.008845  \n",
       "7301  ['htm', 'document', 'us', 'gaap', 'commonclass...        0.019004  \n",
       "7302  ['tmus', 'htm', 'tmus', 'form', 'tmus', 'usdxb...       -0.004576  \n",
       "7303  ['dish', 'htm', 'gaap', 'deferredlongtermliabi...        0.074702  \n",
       "\n",
       "[7304 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34366836",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv('scores.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbbd9baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2033f3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
